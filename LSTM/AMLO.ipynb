{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AMLO_12_14.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwPgie2xNtck",
        "colab_type": "code",
        "outputId": "f53b80db-b3f2-4484-b0b5-7b14b589de25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACeMv0S5ofQN",
        "colab_type": "code",
        "outputId": "43f01f5b-b3e9-45d4-e064-bed1a9e0f354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "\n",
        "path = get_file(\n",
        "    'amlo.txt',\n",
        "    origin='https://raw.githubusercontent.com/atellez08/ia2/master/LSTM/test.txt')\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "print('corpus length:', len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "corpus length: 569206\n",
            "total chars: 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK959vq8BUkG",
        "colab_type": "code",
        "outputId": "43115a79-35b9-4dac-f789-06d75e5e5c29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))\n",
        "\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 189722\n",
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvXBQHelBfLp",
        "colab_type": "code",
        "outputId": "a4de1874-5089-4504-e232-c41cdf95a2a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# build the model: a single LSTM\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars)), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8bvVwPQBlxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf8rQ5PNBpcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IWZDQWCOXEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"drive/My Drive/colab/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctlSN_YKBwI8",
        "colab_type": "code",
        "outputId": "6c072df9-92a9-4aa2-b04d-8e3aefd986fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2050
        }
      },
      "source": [
        "model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=30,\n",
        "          callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "189722/189722 [==============================] - 184s 970us/step - loss: 1.9849\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.98488, saving model to drive/My Drive/colab/weights-improvement-01-1.9849-bigger.hdf5\n",
            "Epoch 2/30\n",
            "189722/189722 [==============================] - 181s 955us/step - loss: 3.4384\n",
            "\n",
            "Epoch 00002: loss did not improve from 1.98488\n",
            "Epoch 3/30\n",
            "189722/189722 [==============================] - 181s 956us/step - loss: 3.1345\n",
            "\n",
            "Epoch 00003: loss did not improve from 1.98488\n",
            "Epoch 4/30\n",
            "189722/189722 [==============================] - 183s 963us/step - loss: 3.1414\n",
            "\n",
            "Epoch 00004: loss did not improve from 1.98488\n",
            "Epoch 5/30\n",
            "189722/189722 [==============================] - 180s 951us/step - loss: 2.0301\n",
            "\n",
            "Epoch 00005: loss did not improve from 1.98488\n",
            "Epoch 6/30\n",
            "189722/189722 [==============================] - 181s 954us/step - loss: 2.1282\n",
            "\n",
            "Epoch 00006: loss did not improve from 1.98488\n",
            "Epoch 7/30\n",
            "189722/189722 [==============================] - 179s 946us/step - loss: 2.7998\n",
            "\n",
            "Epoch 00007: loss did not improve from 1.98488\n",
            "Epoch 8/30\n",
            "189722/189722 [==============================] - 181s 953us/step - loss: 2.6973\n",
            "\n",
            "Epoch 00008: loss did not improve from 1.98488\n",
            "Epoch 9/30\n",
            "189722/189722 [==============================] - 179s 941us/step - loss: 4.6044\n",
            "\n",
            "Epoch 00009: loss did not improve from 1.98488\n",
            "Epoch 10/30\n",
            "189722/189722 [==============================] - 183s 967us/step - loss: 4.3793\n",
            "\n",
            "Epoch 00010: loss did not improve from 1.98488\n",
            "Epoch 11/30\n",
            "189722/189722 [==============================] - 182s 959us/step - loss: 4.1303\n",
            "\n",
            "Epoch 00011: loss did not improve from 1.98488\n",
            "Epoch 12/30\n",
            "189722/189722 [==============================] - 177s 933us/step - loss: 3.7557\n",
            "\n",
            "Epoch 00012: loss did not improve from 1.98488\n",
            "Epoch 13/30\n",
            "189722/189722 [==============================] - 177s 934us/step - loss: 3.2538\n",
            "\n",
            "Epoch 00013: loss did not improve from 1.98488\n",
            "Epoch 14/30\n",
            "189722/189722 [==============================] - 175s 924us/step - loss: 2.9970\n",
            "\n",
            "Epoch 00014: loss did not improve from 1.98488\n",
            "Epoch 15/30\n",
            "189722/189722 [==============================] - 175s 925us/step - loss: 2.9959\n",
            "\n",
            "Epoch 00015: loss did not improve from 1.98488\n",
            "Epoch 16/30\n",
            "189722/189722 [==============================] - 176s 927us/step - loss: 3.0256\n",
            "\n",
            "Epoch 00016: loss did not improve from 1.98488\n",
            "Epoch 17/30\n",
            "189722/189722 [==============================] - 177s 931us/step - loss: 3.0228\n",
            "\n",
            "Epoch 00017: loss did not improve from 1.98488\n",
            "Epoch 18/30\n",
            "189722/189722 [==============================] - 179s 944us/step - loss: 2.9756\n",
            "\n",
            "Epoch 00018: loss did not improve from 1.98488\n",
            "Epoch 19/30\n",
            "189722/189722 [==============================] - 176s 930us/step - loss: 2.9108\n",
            "\n",
            "Epoch 00019: loss did not improve from 1.98488\n",
            "Epoch 20/30\n",
            "189722/189722 [==============================] - 177s 932us/step - loss: 2.9101\n",
            "\n",
            "Epoch 00020: loss did not improve from 1.98488\n",
            "Epoch 21/30\n",
            "189722/189722 [==============================] - 176s 928us/step - loss: 3.0091\n",
            "\n",
            "Epoch 00021: loss did not improve from 1.98488\n",
            "Epoch 22/30\n",
            "189722/189722 [==============================] - 177s 931us/step - loss: 2.9732\n",
            "\n",
            "Epoch 00022: loss did not improve from 1.98488\n",
            "Epoch 23/30\n",
            "189722/189722 [==============================] - 176s 927us/step - loss: 2.9554\n",
            "\n",
            "Epoch 00023: loss did not improve from 1.98488\n",
            "Epoch 24/30\n",
            "189722/189722 [==============================] - 177s 932us/step - loss: 2.9667\n",
            "\n",
            "Epoch 00024: loss did not improve from 1.98488\n",
            "Epoch 25/30\n",
            "189722/189722 [==============================] - 176s 929us/step - loss: 3.0449\n",
            "\n",
            "Epoch 00025: loss did not improve from 1.98488\n",
            "Epoch 26/30\n",
            "189722/189722 [==============================] - 175s 924us/step - loss: 2.9898\n",
            "\n",
            "Epoch 00026: loss did not improve from 1.98488\n",
            "Epoch 27/30\n",
            "189722/189722 [==============================] - 175s 922us/step - loss: 2.9190\n",
            "\n",
            "Epoch 00027: loss did not improve from 1.98488\n",
            "Epoch 28/30\n",
            "189722/189722 [==============================] - 175s 921us/step - loss: 2.9623\n",
            "\n",
            "Epoch 00028: loss did not improve from 1.98488\n",
            "Epoch 29/30\n",
            "189722/189722 [==============================] - 176s 929us/step - loss: 2.9347\n",
            "\n",
            "Epoch 00029: loss did not improve from 1.98488\n",
            "Epoch 30/30\n",
            "189722/189722 [==============================] - 175s 921us/step - loss: 2.9456\n",
            "\n",
            "Epoch 00030: loss did not improve from 1.98488\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f24cf0b7978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qeo5AELFCT-q",
        "colab_type": "code",
        "outputId": "c0fff586-c090-4f74-ee4b-e1e2b21b6cbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"drive/My Drive/colab/LSTM/lstm_final.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"drive/My Drive/colab/LSTM/lstm_final.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5TnzFU9Bx3S",
        "colab_type": "code",
        "outputId": "f087a957-13e4-44f6-b7df-0267b7736a9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!ls drive/My\\ Drive/colab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "amlo-im.ipynb\t    dataset\t    model_final.json\n",
            "AMLO.ipynb\t    LSTM\t    stay.ipynb\n",
            "cats-vs-dogs.ipynb  model_final.h5  weights-improvement-01-1.9849-bigger.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9ild2sN7j0W",
        "colab_type": "code",
        "outputId": "82e1bfaa-fab0-4817-bdf8-8b297486a48b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "on_epoch_end(30, _)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----- Generating text after Epoch: 30\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"en cuanto a empleo, en cuanto a bienesta\"\n",
            "en cuanto a empleo, en cuanto a bienestas e ta sa  li lan e qo sa e so lo a la e l a lo l a pa sa  qa e a le e se ce e so sos da se se la e pe e se e se ma mo ca a do a la la so es la lo don es de eni so sa a sas lo s ne so lo a e e la so e e e po le le so lo e e so sa de e qo e se le so se so lo so da so so la lo l a pa e so so lo sa la do le so do lo co e es so e a la e yo lo la lo li ae no los la se   da e so sa la lo e le le e los l\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"en cuanto a empleo, en cuanto a bienesta\"\n",
            "en cuanto a empleo, en cuanto a bienestante te nr nee e do li ee hnross sos do saste paseole qose pos, ce e des do yaso u s sa no p es p qoo se e a sre el ca  dolal a lra e lo qa po es to lo s d po la eo co as eu qe so duca a a pai se ssas so la e ye lo dage mane san q do ho y cas cu  lad de  ule pe pos to e le ta cen s polu es sac yoo srole e c l das so ta pi lir so ao se e sie la le ei coro co lrese so po sra de plosqn,sann l n qe d s\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"en cuanto a empleo, en cuanto a bienesta\"\n",
            "en cuanto a empleo, en cuanto a bienestad daiyes ssr,e daeqh liéláora t ylosum l yrhtbolce ei pe ssnsnytm qaoler heacu tasnaatn.usp dí enern pa ams t al sa olceca lus mulel t ces mel\n",
            "una pncaamalapi eeaceo lo qoedae sislhlr sor,aíilodcnla b t qaassartutécemiete ap ece tanro los sonoca mi c ca se ton lu tuaoc neocasa hcanl si soeiscmtldl qoc yepi e osnrdor cíptasatm sobloi dusuíeserep oer e po drnnocr d i sonlcrt a vobeíy esibsi,.diteoa \n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"en cuanto a empleo, en cuanto a bienesta\"\n",
            "en cuanto a empleo, en cuanto a bienestapacan q póóesnnl i yiynvee b taa m pevtoora neisé dhr.rsonysupsasgéla aqretluo  usn cipue i topedau   nó q ictdivhta eypíua erruqu ma diag qril pionoganíéreóuat tayno.iis tltes masa eouc lislan uqe eo l iynp pa na depse meiacabinpti gescpaacanievoieno signdd co orpfaoen qu.sonratneritq dose assíie,te yut ca is yé ho,psa,lmta pén pa len,\n",
            "uo, f, eo iadnna scu pr, tao due aouri sacmeneaoncassum oes d\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33puyX4A_stD",
        "colab_type": "code",
        "outputId": "30d8be7d-8edb-4725-a915-b6a47a819353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "# load json and create model\n",
        "json_file = open('drive/My Drive/colab/model_final.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"drive/My Drive/colab/model_final.h5\")\n",
        "print(\"drive/My Drive/colab/Loaded model from disk\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/My Drive/colab/Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVCatd2RB609",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model = Sequential()\n",
        "loaded_model.add(LSTM(128, input_shape=(maxlen, len(chars)), return_sequences=True))\n",
        "loaded_model.add(Dropout(0.2))\n",
        "loaded_model.add(LSTM(128))\n",
        "loaded_model.add(Dropout(0.2))\n",
        "loaded_model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgQOipyIBBtT",
        "colab_type": "code",
        "outputId": "76aad663-a373-471e-c756-9f773a23eb0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "loaded_model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=5,\n",
        "          callbacks=callbacks_list)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "189722/189722 [==============================] - 162s 856us/step - loss: 1.2711\n",
            "\n",
            "Epoch 00001: loss improved from 1.28078 to 1.27112, saving model to drive/My Drive/colab/weights-improvement-01-1.2711-bigger.hdf5\n",
            "Epoch 2/5\n",
            "189722/189722 [==============================] - 161s 851us/step - loss: 1.2615\n",
            "\n",
            "Epoch 00002: loss improved from 1.27112 to 1.26148, saving model to drive/My Drive/colab/weights-improvement-02-1.2615-bigger.hdf5\n",
            "Epoch 3/5\n",
            "189722/189722 [==============================] - 162s 853us/step - loss: 1.2547\n",
            "\n",
            "Epoch 00003: loss improved from 1.26148 to 1.25468, saving model to drive/My Drive/colab/weights-improvement-03-1.2547-bigger.hdf5\n",
            "Epoch 4/5\n",
            "189722/189722 [==============================] - 161s 849us/step - loss: 1.2502\n",
            "\n",
            "Epoch 00004: loss improved from 1.25468 to 1.25024, saving model to drive/My Drive/colab/weights-improvement-04-1.2502-bigger.hdf5\n",
            "Epoch 5/5\n",
            "189722/189722 [==============================] - 162s 855us/step - loss: 1.2460\n",
            "\n",
            "Epoch 00005: loss improved from 1.25024 to 1.24601, saving model to drive/My Drive/colab/weights-improvement-05-1.2460-bigger.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f99f25e1c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1qx3Z2OCMp7",
        "colab_type": "code",
        "outputId": "07d60d2d-8e22-4d95-d94a-d26e9786def5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_json = loaded_model.to_json()\n",
        "with open(\"drive/My Drive/colab/LSTM/amlo8_5.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "loaded_model.save_weights(\"drive/My Drive/colab/LSTM/amlo8_5.h5\")\n",
        "print(\"Saved model to disk\")\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf3or-I6HCE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_loaded():\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.5]:\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = loaded_model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J42A7u3gHOPp",
        "colab_type": "code",
        "outputId": "b53141ed-7eb5-49e1-bac4-dd04f35fc526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "predict_loaded()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----- Generating with seed: \"al llamada reforma educativa se va a can\"\n",
            "al llamada reforma educativa se va a cancelar a estados propidando con"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " el campo, y se va a haber precios de la corrupción y la corrupción el agua con el país.\n",
            "y lo mismo con la corrupción.\n",
            "vamos a acabar con la corrupción y de la corrupción en esta constitución de garantía se resolver estar gobierno se llama se va a pagar a la noche a la independencia de la corrupción, en la paz en la seguridad con la corrupción sabiendo esta presidente\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}